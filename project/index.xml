<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Łukasz Kidziński</title>
    <link>/project/</link>
    <description>Recent content in Projects on Łukasz Kidziński</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Łukasz Kidziński</copyright>
    <lastBuildDate>Wed, 27 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/project/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>DeepArt - Neural style platform</title>
      <link>/project/deepart/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/deepart/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/olj6rktnr40&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34; title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>FreeBoost - MRI segmentation</title>
      <link>/project/freeboost/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/freeboost/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Golf swing analysis app</title>
      <link>/project/kinemai/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/kinemai/</guid>
      <description>&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/SjPP5x1csOc&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34; title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;br&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning how to walk</title>
      <link>/project/deep-learning/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/project/deep-learning/</guid>
      <description>&lt;p&gt;Human movement results from the intricate coordination of muscles, tendons, joints, and other physiological elements. While children learn to walk, run, climb, and jump in their first years of life and most of us can navigate complex environments&amp;ndash;like a crowded street or moving subway&amp;ndash;without considerable active attention, developing controllers that can efficiently and robustly synthesize realistic human motions in a variety of environments remains a grand challenge for biomechanists, neuroscientists, and computer scientists. Current controllers are confined to a small set of pre-specified movements or driven by torques, rather than the complex muscle actuators found in humans.&lt;/p&gt;

&lt;p&gt;To solve these research problems, we created a virtual physiologically accurate musucluskeletal environment in OpenSim software and we set up &lt;a href=&#34;https://www.crowdai.org/challenges/nips-2017-learning-to-run&#34; target=&#34;_blank&#34;&gt;a competition to build models of the brain&lt;/a&gt;. Competition was accepted as one of the 5 official competitions at NIPS 2017. Here is one of the solutions.&lt;/p&gt;

&lt;p&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/mbjuaRg__DI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34; title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;br&gt;
You can find the code on &lt;a href=&#34;http://github.com/stanfordnmbl/osim-rl&#34; target=&#34;_blank&#34;&gt;github&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
